{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load System Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "# Load App Library\n",
    "from FT.StartModelling import StartModelling\n",
    "\n",
    "class StartDPV:\n",
    "    def __init__(self):\n",
    "        self.path = os.getcwd() + '/FT/'\n",
    "\n",
    "    def read_files(self):\n",
    "        lc_hist = pd.read_csv(self.path + '/lc_historical.csv', parse_dates=['earliest_cr_line', 'issue_d'],\n",
    "                              infer_datetime_format=True)\n",
    "        print(lc_hist.head(10))\n",
    "        print(lc_hist.dtypes)\n",
    "        print('preprocessing null perc', lc_hist.isnull().mean() * 100)\n",
    "        # removing variables with 100% NAs, imputing all values for a variable isnt helpful for ML\n",
    "        lc_hist.drop(['all_util', 'inq_last_12m'], axis=1, inplace=True)\n",
    "        # removing col id since it has all unique values and hence wont help with feat. engg.\n",
    "        lc_hist.drop(['id'], axis=1, inplace=True)\n",
    "        return lc_hist\n",
    "\n",
    "    def data_preprocessing(self, lc_hist):\n",
    "        # convert %s to ratio values\n",
    "        lc_hist['revol_util'] = pd.Series(lc_hist.revol_util).str.replace('%', '').astype(float)\n",
    "        lc_hist['percent_bc_gt_75'] = lc_hist.percent_bc_gt_75 / 100\n",
    "\n",
    "        # impute NAs\n",
    "        lc_hist.replace('n/a', np.nan, inplace=True)\n",
    "        lc_hist.dropna(subset=['revol_util'], inplace=True)\n",
    "        lc_hist['emp_length'].replace(to_replace='[^0-9]+', value='', inplace=True, regex=True)\n",
    "        lc_hist['emp_length'] = lc_hist['emp_length'].astype(float)\n",
    "        lc_hist.emp_length.fillna(value=lc_hist.emp_length.median(), inplace=True)\n",
    "        lc_hist.avg_cur_bal.fillna(value=lc_hist.avg_cur_bal.mean(), inplace=True)\n",
    "        lc_hist.acc_open_past_24mths.fillna(value=lc_hist.acc_open_past_24mths.median(), inplace=True)\n",
    "        lc_hist.percent_bc_gt_75.fillna(value=lc_hist.percent_bc_gt_75.mean(), inplace=True)\n",
    "        lc_hist.bc_util.fillna(value=lc_hist.bc_util.mean(), inplace=True)\n",
    "        print('post process null perc ', lc_hist.isnull().mean() * 100)\n",
    "\n",
    "        # Feature Engineering\n",
    "        lc_hist['debt_minus_mortgage'] = lc_hist.dti * (lc_hist.annual_inc / 12.0)\n",
    "        lc_hist['length_cr_line_yrs'] = dt.datetime.today() - df.earliest_cr_line\n",
    "        lc_hist['length_cr_line_yrs'] = lc_hist['length_cr_line_yrs'].dt.days / 365\n",
    "        lc_hist['loan_amnt_to_anninc_ratio'] = lc_hist['loan_amnt'] / lc_hist['annual_inc']\n",
    "        # bin loan amount\n",
    "        bins = [0, 5000, 10000, 15000, 20000, 25000, 40000]\n",
    "        binname = ['0-5000', '5000-10000', '10000-15000', '15000-20000', '20000-25000', '25000 and above']\n",
    "        lc_hist['loan_amnt_binned'] = pd.cut(lc_hist['loan_amnt'], bins, labels=binname)\n",
    "        # Remove Outliers and bin Annual Income\n",
    "        q = lc_hist[\"annual_inc\"].quantile(0.995)\n",
    "        lc_hist = lc_hist[lc_hist[\"annual_inc\"] < q]\n",
    "        bins = [0, 25000, 50000, 75000, 100000, 1000000]\n",
    "        binname = ['0-25000', '25000-50000', '50000-75000', '75000-100000', '100000 and above']\n",
    "        lc_hist['annual_inc_binned'] = pd.cut(lc_hist['annual_inc'], bins, labels=binname)\n",
    "        # bin FICO score\n",
    "        bins = [600, 630, 650, 680, 705, 735, 760, 804, 891]\n",
    "        binname = ['600-630', '630-650', '650-680', '680-705', '705-735', '735-760', '760-804', '804 and above']\n",
    "        lc_hist['fico_range_low_binned'] = pd.cut(lc_hist['fico_range_low'], bins, labels=binname)\n",
    "        return lc_hist\n",
    "\n",
    "    def univariate_plot(self, lc_hist, col, var_type, hue=None):\n",
    "        if var_type == 0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 8))\n",
    "            ax.set_title(\"Distribution Plot\")\n",
    "            sns.distplot(lc_hist[col], ax=ax)\n",
    "        if var_type == 1:\n",
    "            temp = pd.Series(data=hue)\n",
    "            fig, ax = plt.subplots()\n",
    "            width = len(lc_hist[col].unique()) + 6 + 4 * len(temp.unique())\n",
    "            fig.set_size_inches(width, 7)\n",
    "            ax = sns.countplot(data=lc_hist, x=col, order=lc_hist[col].value_counts().index, hue=hue)\n",
    "            if len(temp.unique()) > 0:\n",
    "                for p in ax.patches:\n",
    "                    ax.annotate('{:1.1f}%'.format((p.get_height() * 100) / float(len(lc_hist))),\n",
    "                                (p.get_x() + 0.05, p.get_height() + 20))\n",
    "            else:\n",
    "                for p in ax.patches:\n",
    "                    ax.annotate(p.get_height(), (p.get_x() + 0.32, p.get_height() + 20))\n",
    "            del temp\n",
    "        else:\n",
    "            exit\n",
    "\n",
    "        plt.savefig(self.path + 'uni_analysis_' + col + '.jpg')\n",
    "\n",
    "    def group_summary(self, lc_hist, col):\n",
    "        grp_df = pd.crosstab(lc_hist[col], lc_hist['loan_status'], margins=True)\n",
    "        grp_df['Probability_Charged Off'] = round((grp_df['Charged Off'] / grp_df['All']), 3)\n",
    "        grp_df = grp_df[0:-1]\n",
    "        return grp_df\n",
    "\n",
    "    def bivariate_plot(self, lc_hist, col, stacked=True):\n",
    "        # get data_frame from group_summary function\n",
    "        grp_df = self.group_summary(lc_hist, col)\n",
    "        line_plt = grp_df[['Probability_Charged Off']]\n",
    "        bar_plt = grp_df.iloc[:, 0:2]\n",
    "        ax = line_plt.plot(figsize=(20, 8), marker='o', color='b')\n",
    "        ax2 = bar_plt.plot(kind='bar', ax=ax, rot=1, secondary_y=True, stacked=stacked)\n",
    "        ax.set_title(lc_hist[col].name.title() + ' vs Probability Charge Off', fontsize=20, weight=\"bold\")\n",
    "        ax.set_xlabel(lc_hist[col].name.title(), fontsize=14)\n",
    "        ax.set_ylabel('Probability of Charged off', color='b', fontsize=14)\n",
    "        ax2.set_ylabel('Number of Applicants', color='g', fontsize=14)\n",
    "        plt.savefig(self.path + 'bii_analysis_' + col + '.jpg')\n",
    "\n",
    "    def data_description(self, lc_hist):\n",
    "        self.univariate_plot(lc_hist, 'loan_amnt', 0)\n",
    "        self.univariate_plot(lc_hist, 'annual_inc', 0)\n",
    "        # Used this to remove outliers in Income.\n",
    "        print('annual_inc descriptive', lc_hist['annual_inc'].describe())\n",
    "        self.univariate_plot(lc_hist, 'loan_status', 1)\n",
    "        self.univariate_plot(lc_hist, 'purpose', 1, hue='loan_status')\n",
    "        self.univariate_plot(lc_hist, 'home_ownership', 1, hue='loan_status')\n",
    "        # Correlation Matrix\n",
    "        loan_correlation = lc_hist.corr()\n",
    "        f, ax = plt.subplots(figsize=(14, 9))\n",
    "        sns.heatmap(loan_correlation,\n",
    "                    xticklabels=loan_correlation.columns.values,\n",
    "                    yticklabels=loan_correlation.columns.values, annot=True)\n",
    "        plt.savefig(self.path + 'corr_heatmap.jpg')\n",
    "        # Bi-variate Plots\n",
    "        self.bivariate_plot(lc_hist, 'addr_state')\n",
    "        self.bivariate_plot(lc_hist, 'purpose', stacked=False)\n",
    "        self.bivariate_plot(lc_hist, 'annual_inc_binned')\n",
    "        self.bivariate_plot(lc_hist, 'emp_length')\n",
    "        self.bivariate_plot(lc_hist, 'fico_range_low_binned')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ != \"__main__\":\n",
    "    sdpv = StartDPV()\n",
    "    df = sdpv.read_files()\n",
    "    df = sdpv.data_preprocessing(df)\n",
    "    sdpv.data_description(df)\n",
    "    print(df.dtypes)\n",
    "    # Create Dummy vars\n",
    "    df = pd.get_dummies(df, columns=['loan_amnt_binned', 'annual_inc_binned','addr_state',\n",
    "                                     'fico_range_low_binned', 'purpose', 'home_ownership'], drop_first=True)\n",
    "    drop_features = [ 'fico_range_low', 'percent_bc_gt_75', 'revol_util', 'annual_inc','issue_d', 'earliest_cr_line']\n",
    "    df = df[df.columns[~df.columns.isin(drop_features)]]\n",
    "    sml = StartModelling(df)\n",
    "    sml.GBMClassifier()\n",
    "    sml.ExtraTreesClassify()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
